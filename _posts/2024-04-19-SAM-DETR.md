---
title: "Accelerating DETR Convergence via Semantic-Aligned Matching"
date: 2024-04-19 14:30:00 +09:00
categories: [Paper Reading]
tags:
   [
    Object Detection,
    DETR
   ]
use_math: true
--- 


# Accelerating DETR Convergence via Semantic-Aligned Matching
[CVPR 2022](https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Accelerating_DETR_Convergence_via_Semantic-Aligned_Matching_CVPR_2022_paper.html), 2024-04-19 기준 78회 인용

## Task
- Object Detection
- DETR

## Contribution
- 기존의 DETR 들에서 encoded image feature와 object query 가 cross-attention 하는 부분이 문제가 있다고 지적
- encoded image feature 와 object query 의 semantic embedding spaces 가 서로 다르다 → slow convergence
- Semantic-Aligned-Matching DETR (SAM-DETR) 구조를 제안
  - Cross-Attention 전에 align을 맞춰주는 모듈을 추가
  - Encoded image feature, Object queries, reference boxes 들을 활용
- SAM 구조를 SMCA-DETR (Spatially Modulated Co-Attention) 에 적용해서 성능을 향상

## Proposed Method

<img src="/images/sam-detr/fig1.png" width="450px" alt="alt">

기존의 방법들보다 convergence가 빠르다 <br>
SMCA 에 붙이면 더 좋다

#### A Review of DETR

<img src="/images/sam-detr/fig2.png" width="450px" alt="alt">

<img src="/images/sam-detr/eq1.png" width="350px" alt="alt">

본 논문에서는 cross-attention 부분을 matching & Distillation 으로 나눠서 설명 <br>
Encoder feature 와 Object query 와의 연산으로 attention weight map 을 만드는 부분을 matching <br>
해당 attention weight map으로 encoder feature (value) 에 연산하는 부분을 Distillation <br>
Figure 2에서 볼 수 있듯이 각 쿼리에 대한 attention weights는 관련있는 Region에 값이 커진다 <br>
하지만 기존의 방법은 initialization 으로 부터 relevant regions을 찾아 매칭하기 위해서는 많은 학습이 필요하다.

<img src="/images/sam-detr/fig3.png" width="650px" alt="alt">

#### Semantic-Aligned Matching

<img src="/images/sam-detr/eq2_3.png" width="350px" alt="alt">

$H \times W \times d$ 크기의 feature map 에서 reference box를 기반으로 region-level features 를 추출

<img src="/images/sam-detr/code.png" width="550px" alt="alt">

reference box에 대해서 논문에서 추가적인 설명이 없어 코드로 확인 <br>
(num queries x 4) 사이즈의 embedding 을 사용

#### Matching with Salient Point Features

<img src="/images/sam-detr/eq4.png" width="350px" alt="alt">

ConvNet + MLP 를 통해서 region-level features로 부터 M개 salient point 추출 → 논문 표현

코드 확인 부분
- reference box는 object query 개수 만큼 존재
- region-level feature 도 object query 개수 만큼 존재
- salient point 도 object query 개수 만큼 존재

<img src="/images/sam-detr/eq5.png" width="450px" alt="alt">

region-level features 에서 salient point 로 object query 추출

<img src="/images/sam-detr/eq6.png" width="400px" alt="alt">

positional embedding

<img src="/images/sam-detr/eq7_8.png" width="400px" alt="alt">

이전까지의 object query 를 기반으로 새로 구해진 object query reweighting

#### Compatibility with SMCA-DETR

Semantic-Aligned Matching 방법을 SMCA-DETR에 적용

아래 수식 3, 4 는 SMCA-DETR 논문 수식

<img src="/images/sam-detr/eq_smca_3.png" width="400px" alt="alt">

<img src="/images/sam-detr/eq_smca_4.png" width="400px" alt="alt">

salient point를 center point로 사용 <br>
ROI feature로 부터 scale도 prediction <br>
Gaussian-like weight map 을 만들어서 cross-attention weight map에 더해줌

## Experimental Results

<img src="/images/sam-detr/fig4.png" width="650px" alt="alt">

salient points 시각화 <br>
multi-head 에 대한 결과들을 시각화

<img src="/images/sam-detr/tab1.png" width="650px" alt="alt">

COCO dataset 에 대한 실험 결과