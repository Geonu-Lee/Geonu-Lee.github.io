---
title: "Supervision Interpolation via LossMix: Generalizing Mixup for Object Detection and Beyond"
date: 2024-03-04 22:00:00 +09:00
categories: [Paper Reading]
tags:
   [
    Object Detection,
    Data Augmentation,
    Domain Adaptation
   ]
use_math: true
--- 

# Supervision Interpolation via LossMix: Generalizing Mixup for Object Detection and Beyond
[AAAI 2024](https://arxiv.org/html/2303.10343v2), 2024-03-04 기준 2회 인용


## Task
- Object Detection
- Data Augmentation
- Domain Adaptation


## Contribution
- Classification 에서 data augmentation 을 위해서 Mixup 했던 방식을 Object Detection 에 적용하기에는 한계가 존재
- Spatial misalignment 문제가 존재 (bounding box 를 Mixup 했을 경우)
- Supervision Interpolation 으로 해결하겠다


## Motivation
<img src="/images/LossMix/fig2.png" width="550px" alt="alt">

기존의 Mixup 하는 방식을 사용했을 경우 왼쪽과 같이 잘못 Interpolation 된 box가 생성된다

다양한 bounding box coordinates 으로 구성되어 있기 때문에 ground truth 의 localization 을 방해하지 않고서는 naively 하게 mixup 할 수 없다

<img src="/images/LossMix/fig3.png" width="550px" alt="alt">

비율을 두고 mixup 을 하고 label 까지 같이 mixup 을 했을 때 noisy data 가 될 수 있다

<img src="/images/LossMix/fig1.png" width="550px" alt="alt">

이미지끼리 mixup 한 이미지를 각각의 label 마다 Loss 부여 -> Supervision Interpolation

## Proposed Method
<img src="/images/LossMix/eq1_2.png" width="450px" alt="alt">

<img src="/images/LossMix/eq3.png" width="450px" alt="alt">

일반적인 Mixup 방식 <br>
-> Figure 3 에서와 같이 Noisy data 가 될 수 있다

### Supervision Interpolation

<img src="/images/LossMix/eq4_5.png" width="450px" alt="alt">

이미지만 서로 Mixup <br>
5번 수식과 같이 Supervision Interpolation 하겠다 <br>
Loss 를 Interpolation

### LossMix

<img src="/images/LossMix/eq6.png" width="450px" alt="alt">

<img src="/images/LossMix/eq8.png" width="450px" alt="alt">

수식 4번, 5번과 거의 동일하지만.. <br>
Mixup 된 이미지를 각 Label 에 대해서 Loss 계산 <br>
$\lambda$ 를 통해서 interpolation

<img src="/images/LossMix/eq9-14.png" width="450px" alt="alt">

classification 관점에서 봤을 때 <br>
수식 10번은 여기서 제안하는 LossMix <br>
수식 13번은 label 까지 Mixup 해서 학습하는 방식 <br>
이 두개가 결국 전개하면 같다 -> LossMix 가 수식 13번과 동일한 효과를 낼 수 있다

<img src="/images/LossMix/eq15.png" width="450px" alt="alt">

<img src="/images/LossMix/eq16.png" width="450px" alt="alt">

Object Detection (Faster RCNN) 에 적용

### Domain Adaptation

Adative Teacher 를 사용 <br>
(Appendix 이미지 첨부)

<img src="/images/LossMix/warmup.png" width="650px" alt="alt">

Warmup Phase <br>
Source domain 끼리 Mixup <br>
Source domain 과 target domain 의 unlabel data 와 Mixup (이미지만) <br>

<img src="/images/LossMix/adaptation.png" width="650px" alt="alt">

Adaptation Phase <br>
Source - Source <br>
Target (pseudo-label) - Target (pseudo-label) <br>
Source - Target (pseudo-label) 


## Experimental Results

<img src="/images/LossMix/tab1.png" width="450px" alt="alt">

PASCAL VOC 에서의 실험결과 <br>
Faster RCNN 에 적용했을 때 성능이 제일 좋다

<img src="/images/LossMix/tab2.png" width="650px" alt="alt">

COCO 에서도 좋다

<img src="/images/LossMix/tab3.png" width="650px" alt="alt">

Ablation Study

<img src="/images/LossMix/tab4.png" width="650px" alt="alt">

Domain Adaptation 실험 결과